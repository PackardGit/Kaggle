{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle glasses comp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhyoXnGFcweV",
        "outputId": "3de415ce-03a3-4ead-8cf9-6ca92de497df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# montowanie google dysku #\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "COLAB = True\n",
        "print(\"Note: using Google CoLab\")\n",
        "\n",
        "# formatowanie czasu #\n",
        "import time \n",
        "def time_elapsed(sec):\n",
        "  h = int(sec/3600)\n",
        "  m = int(sec/60)\n",
        "  s = sec % 60\n",
        "  return \"{}:{>02}:{:>05.2f}\".format(h,m,s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbm-UrBahW8U"
      },
      "source": [
        "# pobranie i formatowanie danych #\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "PATH = '/content/drive/My Drive/projects/glasses'\n",
        "DATA_PATH = '/content/drive/My Drive/projects/glasses/train.csv'\n",
        "SUBMIT_DATA_PATH = '/content/drive/My Drive/projects/glasses/test.csv'\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(DATA_PATH,na_values=['NA','?'])\n",
        "df_submit = pd.read_csv(SUBMIT_DATA_PATH,na_values=['NA','?'])\n",
        "\n",
        "x_columns = df.columns.drop('id').drop('glasses')\n",
        "x_submit_columns = df_submit.columns.drop('id')\n",
        "\n",
        "x_submit = df_submit[x_submit_columns].values\n",
        "x = df[x_columns].values\n",
        "y = df['glasses'].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rYczXSNZgzO",
        "outputId": "3031ee3f-98d2-4b25-9e2a-5ed47b8bc55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# stworzenie własnej sieci neuronowej\n",
        "import tensorflow.keras.initializers\n",
        "import statistics\n",
        "import tensorflow.keras\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import math\n",
        "\n",
        "def mlogloss(y_test, preds): # funckja \n",
        "    epsilon = 1e-15\n",
        "    sum = 0\n",
        "    for row in zip(preds,y_test):\n",
        "        x = row[0][row[1]]\n",
        "        x = max(epsilon,x)\n",
        "        x = min(1-epsilon,x)\n",
        "        sum+=math.log(x)\n",
        "    return( (-1/len(preds))*sum)\n",
        "\n",
        "def build_snn(input_size):\n",
        "    neuronPct = 0.559  # parametry zooptymalizowane za pomoca BayesianOplimization\n",
        "    neuronShrink = 0.3227\n",
        "    dropout = 0.1526\n",
        "    lr = 0.06767\n",
        "    neuronCount = int(neuronPct * 1000)   \n",
        "    model = Sequential()\n",
        "    layer = 0\n",
        "    while neuronCount>25 and layer<10:\n",
        "        # The first (0th) layer needs an input input_dim(neuronCount)\n",
        "        if layer==0:\n",
        "            model.add(Dense(neuronCount,input_dim=input_size,activation=PReLU()))\n",
        "        else:\n",
        "            model.add(Dense(neuronCount, activation=PReLU())) \n",
        "        layer += 1\n",
        "        # Add dropout after each hidden layer\n",
        "        model.add(Dropout(dropout))\n",
        "        # Shrink neuron count for each layer\n",
        "        neuronCount = neuronCount * neuronShrink\n",
        "    model.add(Dense(1,activation='sigmoid')) # Output\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr))\n",
        "    return model\n",
        "\n",
        "def blend_ensamble(x,y,x_submit):\n",
        "  FOLDS = 10 # podzielenie danych treningowych na 10 czesci\n",
        "  kf = StratifiedKFold(FOLDS)\n",
        "  folds = list(kf.split(x,y))\n",
        "\n",
        "  models = [\n",
        "            KerasClassifier(build_fn = build_snn, input_size=x.shape[1]),\n",
        "            RandomForestClassifier(n_estimators=100,n_jobs=-1,criterion='gini'),\n",
        "            RandomForestClassifier(n_estimators=100,n_jobs=-1,criterion='entropy'),\n",
        "            ExtraTreesClassifier(n_estimators=100,n_jobs=-1,criterion='gini'),\n",
        "            ExtraTreesClassifier(n_estimators=100,n_jobs=-1,criterion='entropy'),\n",
        "            GradientBoostingClassifier(learning_rate=0.05,subsample=0.5,max_depth=6,n_estimators=50)]\n",
        "\n",
        "  dataset_blend_train = np.zeros((x.shape[0], len(models))) # każdy model wypracuje jedna wartosc dla jednej danej\n",
        "  dataset_blend_test = np.zeros((x_submit.shape[0], len(models))) \n",
        "\n",
        "  for j, model in enumerate(models): # dla każdego modelu\n",
        "    print(f'{j} Model: {model}')\n",
        "    fold_sums = np.zeros((x_submit.shape[0],len(folds))) # dla każdego zestawu danych wyznaczone beda predyckje i wysrednione\n",
        "    total_loss = 0\n",
        "    for i, (train,test) in enumerate(folds):  # dla każdego zestawu danych treningowych\n",
        "      x_train = x[train]\n",
        "      y_train = y[train]\n",
        "      x_test = x[test] # x testowe ale ze zbioru treningowego\n",
        "      y_test = y[test]\n",
        "      if j == 0:\n",
        "        model.fit(x_train,y_train,epochs=50,verbose=0)\n",
        "      else:\n",
        "        model.fit(x_train,y_train)\n",
        "      pred = np.array(model.predict_proba(x_test))\n",
        "      pred_submit = np.array(model.predict_proba(x_submit))\n",
        "      dataset_blend_train[test,j] = pred[:,1] # zapisanie predykcji dla danego modelu oraz danego zestawu danych\n",
        "      fold_sums[:,i] = pred_submit[:,1] # dla kazdego zestawu danych policzyc predykcje\n",
        "      loss = mlogloss(y_test,pred) # policzenie pomocniczej funkcji celu\n",
        "      total_loss+=loss # liczenie sumy funkcji celu dla modelu\n",
        "      print(f'Fold {i} has loss: {loss}') \n",
        "    print(\"{}: Mean loss={}\".format(model.__class__.__name__,total_loss/len(folds)))\n",
        "    dataset_blend_test[:,j] = fold_sums.mean(1) # wyznaczenie jednej predykcji dla jednego modelu\n",
        "  \n",
        "  print('Blending Models')\n",
        "  # wyznaczenie ostatecznej predykcji za pomoca regresji logistycznej\n",
        "# ostateczne predykcja na podstawie predykcji wszystkich modeli\n",
        "  return dataset_blend_train,dataset_blend_test\n",
        "def stretch(y):\n",
        "    return (y - y.min()) / (y.max() - y.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-bcd28f045b15>\"\u001b[0;36m, line \u001b[0;32m66\u001b[0m\n\u001b[0;31m    GradientBoostingClassifier(learning_rate=0.05,subsample=0.5,max_depth=6,n_estimators=50)]\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T38tMSdQPyz",
        "outputId": "1194c35b-4313-4b61-98df-3f088ee127a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "(dataset_blend_train,dataset_blend_test) = blend_ensamble(x,y,x_submit)\n",
        "#submit_data = stretch(submit_data)\n",
        "\n",
        "blend = LogisticRegression(solver='lbfgs') \n",
        "blend.fit(dataset_blend_train,y) \n",
        "wynik=blend.predict_proba(dataset_blend_test) \n",
        "\n",
        "submit_data = stretch(wynik)\n",
        "\n",
        "    ####################\n",
        "    # Build submit file\n",
        "    ####################\n",
        "ids = [id+1 for id in range(submit_data.shape[0])]\n",
        "submit_filename = os.path.join(PATH, \"glasses_submit.csv\")\n",
        "submit_df = pd.DataFrame({'FaceID': ids, \n",
        "                              'GlassesProbability': \n",
        "                              submit_data[:, 1]},\n",
        "                             columns=['FaceID',\n",
        "                            'GlassesProbability'])\n",
        "submit_df.to_csv(submit_filename, index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Model: <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f5ddd4efbe0>\n",
            "Fold 0 has loss: 0.3070113457325397\n",
            "Fold 1 has loss: 0.4605170185988092\n",
            "Fold 2 has loss: 1.3815510557964268\n",
            "Fold 3 has loss: 0.07675283643313487\n",
            "Fold 4 has loss: 0.6907755278982138\n",
            "Fold 5 has loss: 0.1535056728662701\n",
            "Fold 6 has loss: 0.537269855031944\n",
            "Fold 7 has loss: 0.0767528364331349\n",
            "Fold 8 has loss: 0.4605170185988091\n",
            "Fold 9 has loss: 0.23025850929940458\n",
            "KerasClassifier: Mean loss=0.43749116766886875\n",
            "1 Model: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "Fold 0 has loss: 0.3387758321541058\n",
            "Fold 1 has loss: 0.3440309533180741\n",
            "Fold 2 has loss: 0.3474443226373117\n",
            "Fold 3 has loss: 0.3492422514115648\n",
            "Fold 4 has loss: 0.3404680378153357\n",
            "Fold 5 has loss: 0.3389947273559876\n",
            "Fold 6 has loss: 0.34258755948463304\n",
            "Fold 7 has loss: 0.33171041394335404\n",
            "Fold 8 has loss: 0.34444725331710485\n",
            "Fold 9 has loss: 0.33582964350041056\n",
            "RandomForestClassifier: Mean loss=0.3413530994937882\n",
            "2 Model: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                     criterion='entropy', max_depth=None, max_features='auto',\n",
            "                     max_leaf_nodes=None, max_samples=None,\n",
            "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                     min_samples_leaf=1, min_samples_split=2,\n",
            "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
            "                     oob_score=False, random_state=None, verbose=0,\n",
            "                     warm_start=False)\n",
            "Fold 0 has loss: 0.34725059087496174\n",
            "Fold 1 has loss: 0.345476210282963\n",
            "Fold 2 has loss: 0.35068013073957294\n",
            "Fold 3 has loss: 0.35679719661376275\n",
            "Fold 4 has loss: 0.34333115193478403\n",
            "Fold 5 has loss: 0.3517306581035616\n",
            "Fold 6 has loss: 0.3440998213133943\n",
            "Fold 7 has loss: 0.33930938698924357\n",
            "Fold 8 has loss: 0.34460954919015635\n",
            "Fold 9 has loss: 0.3401610933877086\n",
            "ExtraTreesClassifier: Mean loss=0.3463445789430108\n",
            "Blending Models\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-552c28b00d3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmit_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msubmit_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"glasses_submit.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m submit_df = pd.DataFrame({'FaceID': ids, \n\u001b[1;32m     16\u001b[0m                               \u001b[0;34m'GlassesProbability'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PATH' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5sLmTnyaiNu"
      },
      "source": [
        "\n",
        "#submit_data= np.around([submit_data])\n",
        "\n",
        "PATH = '/content/drive/My Drive/projects/glasses'\n",
        "\n",
        "ids = [id+4501 for id in range(submit_data.shape[0])]\n",
        "submit_filename = os.path.join(PATH, \"glasses_submit.csv\")\n",
        "submit_df = pd.DataFrame({'ID': ids, \n",
        "                              'Glasses': \n",
        "                              submit_data[:, 1]},\n",
        "                             columns=['ID',\n",
        "                            'Glasses'])\n",
        "submit_df.to_csv(submit_filename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR2r0UeeLGiy",
        "outputId": "c7c37749-c7d8-4960-92a4-1a456ab339c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "submit_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}